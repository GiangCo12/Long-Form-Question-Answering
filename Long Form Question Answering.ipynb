{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /Users/user/anaconda3/lib/python3.11/site-packages (7.17.9)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from elasticsearch) (1.26.16)\n",
      "Requirement already satisfied: certifi in /Users/user/anaconda3/lib/python3.11/site-packages (from elasticsearch) (2024.8.30)\n",
      "Requirement already satisfied: faiss_cpu in /Users/user/anaconda3/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from faiss_cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/user/anaconda3/lib/python3.11/site-packages (from faiss_cpu) (23.1)\n",
      "Requirement already satisfied: nlp in /Users/user/anaconda3/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (11.0.0)\n",
      "Requirement already satisfied: dill in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (0.3.1.1)\n",
      "Requirement already satisfied: pandas in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (4.65.0)\n",
      "Requirement already satisfied: filelock in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (3.9.0)\n",
      "Requirement already satisfied: xxhash in /Users/user/anaconda3/lib/python3.11/site-packages (from nlp) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->nlp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->nlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->nlp) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->nlp) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/user/anaconda3/lib/python3.11/site-packages (from pandas->nlp) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from pandas->nlp) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from pandas->nlp) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/user/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->nlp) (1.16.0)\n",
      "Requirement already satisfied: transformers in /Users/user/anaconda3/lib/python3.11/site-packages (4.46.0.dev0)\n",
      "Requirement already satisfied: filelock in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/user/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/user/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: apache_beam in /Users/user/anaconda3/lib/python3.11/site-packages (2.59.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (3.10.7)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (1.9.7)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (1.66.2)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (4.17.3)\n",
      "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (3.3.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (1.26.4)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.7.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (23.1)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (4.10.1)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (4.25.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (2023.3.post1)\n",
      "Requirement already satisfied: redis<6,>=5.0.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (5.1.1)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (2022.7.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (4.10.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.19.0)\n",
      "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (11.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.6)\n",
      "Requirement already satisfied: js2py<1,>=0.74 in /Users/user/anaconda3/lib/python3.11/site-packages (from apache_beam) (0.74)\n",
      "Requirement already satisfied: docopt in /Users/user/anaconda3/lib/python3.11/site-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (0.6.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/user/anaconda3/lib/python3.11/site-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.0.9)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /Users/user/anaconda3/lib/python3.11/site-packages (from js2py<1,>=0.74->apache_beam) (5.2)\n",
      "Requirement already satisfied: pyjsparser>=2.5.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from js2py<1,>=0.74->apache_beam) (2.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (0.18.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/user/anaconda3/lib/python3.11/site-packages (from pymongo<5.0.0,>=3.8.0->apache_beam) (2.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch\n",
    "!pip install faiss_cpu\n",
    "!pip install nlp    \n",
    "!pip install transformers\n",
    "!pip install apache_beam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "eli5 = nlp.load_dataset('eli5')\n",
    "wiki40b_snippets = nlp.load_dataset('wiki_snippets', name='wiki40b_en_100_0')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_eli5': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 272634), 'validation_eli5': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 9812), 'test_eli5': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 24512), 'train_asks': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 131778), 'validation_asks': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 2281), 'test_asks': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 4462), 'train_askh': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 98525), 'validation_askh': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 4901), 'test_askh': Dataset(features: {'q_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'selftext': Value(dtype='string', id=None), 'document': Value(dtype='string', id=None), 'subreddit': Value(dtype='string', id=None), 'answers': Sequence(feature={'a_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'score': Value(dtype='int32', id=None)}, length=-1, id=None), 'title_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'selftext_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None), 'answers_urls': Sequence(feature={'url': Value(dtype='string', id=None)}, length=-1, id=None)}, num_rows: 9764)}\n"
     ]
    }
   ],
   "source": [
    "print(eli5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/__main__.py\", line 24, in <module>\n",
      "    sys.exit(_main())\n",
      "             ^^^^^^^\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/main.py\", line 78, in main\n",
      "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
      "    module = importlib.import_module(module_path)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/commands/install.py\", line 16, in <module>\n",
      "    from pip._internal.cli.req_command import (\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/req_command.py\", line 19, in <module>\n",
      "    from pip._internal.index.package_finder import PackageFinder\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/index/package_finder.py\", line 31, in <module>\n",
      "    from pip._internal.req import InstallRequirement\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/req/__init__.py\", line 9, in <module>\n",
      "    from .req_install import InstallRequirement\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/req/req_install.py\", line 40, in <module>\n",
      "    from pip._internal.operations.install.wheel import install_wheel\n",
      "  File \"/Users/user/anaconda3/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py\", line 55, in <module>\n",
      "    from pip._internal.utils.unpacking import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1069, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 729, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/user')\n",
    "from lfqa_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '8houtx',\n",
       " 'title': 'Why does water heated to room temperature feel colder than the air around it?',\n",
       " 'selftext': '',\n",
       " 'document': '',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dylcnfk', 'dylcj49'],\n",
       "  'text': [\"Water transfers heat more efficiently than air. When something feels cold it's because heat is being transferred from your skin to whatever you're touching. Since water absorbs the heat more readily than air, it feels colder.\",\n",
       "   \"Air isn't as good at transferring heat compared to something like water or steel (sit on a room temperature steel bench vs. a room temperature wooden bench, and the steel one will feel more cold).\\n\\nWhen you feel cold, what you're feeling is heat being transferred out of you.  If there is no breeze, you feel a certain way.  If there's a breeze, you will get colder faster (because the moving air is pulling the heat away from you), and if you get into water, its quite good at pulling heat from you.   Get out of the water and have a breeze blow on you while you're wet, all of the water starts evaporating, pulling even more heat from you.\"],\n",
       "  'score': [5, 2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': []}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5['test_eli5'][12345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '{\"nlp_id\": 1665419, \"wiki_id\": \"Q179635\", \"sp\": 12, \"sc\": 653, \"ep\": 12, \"ec\": 1223}',\n",
       " 'article_title': 'Heat transfer',\n",
       " 'end_character': 1223,\n",
       " 'end_paragraph': 12,\n",
       " 'nlp_id': 1665419,\n",
       " 'passage_text': 'from one place to another place without the movement of particles is called conduction, such as when placing a hand on a cold glass of water - heat is conducted from the warm skin to the cold glass, but if the hand is held a few inches from the glass, little conduction would occur since air is a poor conductor of heat. Steady state conduction is an idealized model of conduction that happens when the temperature difference driving the conduction is constant, so that after a time, the spatial distribution of temperatures in the conducting object does not change any',\n",
       " 'section_title': 'Conduction',\n",
       " 'start_character': 653,\n",
       " 'start_paragraph': 12,\n",
       " 'wiki_id': 'Q179635'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki40b_snippets[8991855]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    [{'host': 'localhost', 'port': 9200, 'scheme': 'http'}],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 83, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/1s7c462d1g77twlp95_rgycm0000gn/T/ipykernel_24988/1593372765.py:36: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  response = es_client.search(\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Kết nối đến Elasticsearch\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Đặt tên chỉ mục\n",
    "index_name = 'wiki40b_snippets_100w'\n",
    "\n",
    "# Cấu hình chỉ mục\n",
    "index_config = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"article_title\": {\"type\": \"text\"},\n",
    "            \"section_title\": {\"type\": \"text\"},\n",
    "            \"passage_text\": {\"type\": \"text\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Tạo chỉ mục nếu chưa tồn tại\n",
    "if not es_client.indices.exists(index=index_name):\n",
    "    es_client.indices.create(index=index_name, body=index_config, headers={\"Content-Type\": \"application/json\"})\n",
    "\n",
    "# Đặt truy vấn và số lượng kết quả\n",
    "q = 'your query here'  # Đặt truy vấn của bạn vào đây\n",
    "n_results = 10  # Số lượng kết quả bạn muốn\n",
    "\n",
    "# Loại bỏ các từ bị cấm\n",
    "banned = ['how', 'why', 'what', 'where', 'which', 'do', 'does', 'is', '?', 'eli5', 'eli5:']\n",
    "q = ' '.join([w for w in q.split() if w not in banned])\n",
    "\n",
    "# Gửi truy vấn tìm kiếm\n",
    "response = es_client.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": q,\n",
    "                \"fields\": [\"article_title\", \"section_title\", \"passage_text^2\"],\n",
    "                \"type\": \"cross_fields\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": n_results,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Xử lý kết quả tìm kiếm\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not es_client.indices.exists(index='wiki40b_snippets_100w'):\n",
    "    make_es_index_snippets(es_client, wiki40b_snippets, index_name='wiki40b_snippets_100w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_es_index(question, es_client, index_name, size=10):\n",
    "    query_body = {\n",
    "        \"size\": size,  # Thêm tham số size vào đây\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": question\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Thực hiện truy vấn Elasticsearch\n",
    "    res = es_client.search(index=index_name, body=query_body)\n",
    "    \n",
    "    # Xử lý kết quả trả về\n",
    "    res_list = [\n",
    "        {\n",
    "            'article_title': hit['_source']['article_title'],\n",
    "            'section_title': hit['_source']['section_title'],\n",
    "            'passage_text': hit['_source']['passage_text']\n",
    "        }\n",
    "        for hit in res['hits']['hits']\n",
    "    ]\n",
    "    \n",
    "    return res, res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/1s7c462d1g77twlp95_rgycm0000gn/T/ipykernel_24988/1084859799.py:12: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res = es_client.search(index=index_name, body=query_body)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0acb5_row0_col0, #T_0acb5_row0_col1, #T_0acb5_row0_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0acb5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0acb5_level0_col0\" class=\"col_heading level0 col0\" >Article</th>\n",
       "      <th id=\"T_0acb5_level0_col1\" class=\"col_heading level0 col1\" >Sections</th>\n",
       "      <th id=\"T_0acb5_level0_col2\" class=\"col_heading level0 col2\" >Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0acb5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0acb5_row0_col0\" class=\"data row0 col0\" >---</td>\n",
       "      <td id=\"T_0acb5_row0_col1\" class=\"data row0 col1\" >---</td>\n",
       "      <td id=\"T_0acb5_row0_col2\" class=\"data row0 col2\" >--- Why does water heated to room temperature feel colder than the air around it?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x6aac4dd10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = eli5['test_eli5'][12345]['title']\n",
    "doc, res_list = query_es_index(question, es_client, index_name='wiki40b_snippets_100w', size=10)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Article': ['---'] + [res['article_title'] for res in res_list],\n",
    "    'Sections': ['---'] + [res['section_title'] if res['section_title'].strip() != '' else res['article_title']\n",
    "                 for res in res_list],\n",
    "    'Text': ['--- ' + question] + [res['passage_text'] for res in res_list],\n",
    "})\n",
    "df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "# Set the device      \n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available())  # Kiểm tra xem MPS có được hỗ trợ không\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ELI5DatasetQARetriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/user/Downloads/Long Form Question Answering.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m checkpoint[\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Chuẩn bị dataset (bạn cần định nghĩa hoặc import ELI5DatasetQARetriver)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Đảm bảo rằng ELI5DatasetQARetriver đã được định nghĩa trước đó\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X20sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m qar_train_dset \u001b[39m=\u001b[39m ELI5DatasetQARetriver(eli5[\u001b[39m'\u001b[39m\u001b[39mtrain_eli5\u001b[39m\u001b[39m'\u001b[39m], training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m qar_valid_dset \u001b[39m=\u001b[39m ELI5DatasetQARetriver(eli5[\u001b[39m'\u001b[39m\u001b[39mvalidation_eli5\u001b[39m\u001b[39m'\u001b[39m], training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Tải mô hình BERT đã huấn luyện trước\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ELI5DatasetQARetriver' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "class ArgumentsQAR():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 512\n",
    "        self.max_length = 128\n",
    "        self.checkpoint_batch_size = 32\n",
    "        self.print_freq = 100\n",
    "        self.pretrained_model_name = \"google/bert_uncased_L-8_H-768_A-12\"\n",
    "        self.model_save_name = \"retriever_models/eli5_retriever_model_l-8_h-768_b-512-512\"\n",
    "        self.learning_rate = 2e-4\n",
    "        self.num_epochs = 10\n",
    "\n",
    "qar_args = ArgumentsQAR()\n",
    "\n",
    "# Tạo thư mục để lưu mô hình nếu chưa tồn tại\n",
    "if not os.path.exists('retriever_models'):\n",
    "    os.makedirs('retriever_models')\n",
    "\n",
    "# Hàm lưu checkpoint\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, model_save_name):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict()\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, f\"{model_save_name}_checkpoint_{epoch}.pth\")\n",
    "    print(f\"Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "# Hàm tải lại checkpoint\n",
    "def load_checkpoint(model, optimizer, scheduler, model_save_name, epoch):\n",
    "    checkpoint = torch.load(f\"{model_save_name}_checkpoint_{epoch}.pth\", map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    print(f\"Checkpoint loaded from epoch {epoch}\")\n",
    "    return checkpoint['epoch']\n",
    "\n",
    "# Chuẩn bị dataset (bạn cần định nghĩa hoặc import ELI5DatasetQARetriver)\n",
    "# Đảm bảo rằng ELI5DatasetQARetriver đã được định nghĩa trước đó\n",
    "qar_train_dset = ELI5DatasetQARetriver(eli5['train_eli5'], training=True)\n",
    "qar_valid_dset = ELI5DatasetQARetriver(eli5['validation_eli5'], training=False)\n",
    "\n",
    "# Tải mô hình BERT đã huấn luyện trước\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=qar_args.pretrained_model_name,\n",
    "    from_file=None,\n",
    "    device=\"mps\"  # Sử dụng MPS\n",
    ")\n",
    "\n",
    "# Khởi tạo optimizer và scheduler\n",
    "qar_optimizer = torch.optim.AdamW(qar_model.parameters(), lr=qar_args.learning_rate)\n",
    "qar_scheduler = torch.optim.lr_scheduler.StepLR(qar_optimizer, step_size=1)\n",
    "\n",
    "# Khôi phục từ checkpoint (nếu có checkpoint đã lưu)\n",
    "last_epoch = 0  # Bắt đầu từ epoch 0\n",
    "try:\n",
    "    last_epoch = load_checkpoint(qar_model, qar_optimizer, qar_scheduler, qar_args.model_save_name, 532)  # Sử dụng epoch 532\n",
    "except FileNotFoundError:\n",
    "    print(\"Checkpoint không tồn tại, bắt đầu huấn luyện từ epoch 0.\")\n",
    "\n",
    "# Huấn luyện mô hình từ epoch đã lưu\n",
    "for e in range(last_epoch, qar_args.num_epochs):\n",
    "    train_qa_retriever(qar_model, qar_tokenizer, qar_train_dset, qar_valid_dset, qar_args)\n",
    "    save_checkpoint(qar_model, qar_optimizer, qar_scheduler, e, qar_args.model_save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1debd7b446204ac68a2355eca71dc8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/487 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bee34cdee104756be24a074763a045b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7437efd8194e8a96dde6f881f609c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb084ca99754e468047872dcecaf1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/325M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'RetriBertConfig' object has no attribute 'position_embedding_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/user/Downloads/Long Form Question Answering.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qar_tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39myjernite/retribert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m qar_model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39myjernite/retribert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/user/Downloads/Long%20Form%20Question%20Answering.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m _ \u001b[39m=\u001b[39m qar_model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:4053\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4047\u001b[0m config \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   4048\u001b[0m     config, use_flash_attention_2\u001b[39m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[39m=\u001b[39mtorch_dtype, device_map\u001b[39m=\u001b[39mdevice_map\n\u001b[1;32m   4049\u001b[0m )\n\u001b[1;32m   4051\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   4052\u001b[0m     \u001b[39m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 4053\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(config, \u001b[39m*\u001b[39mmodel_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   4055\u001b[0m \u001b[39m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   4056\u001b[0m config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/deprecated/retribert/modeling_retribert.py:87\u001b[0m, in \u001b[0;36mRetriBertModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection_dim \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mprojection_dim\n\u001b[0;32m---> 87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_query \u001b[39m=\u001b[39m BertModel(config)\n\u001b[1;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_doc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mshare_encoders \u001b[39melse\u001b[39;00m BertModel(config)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(config\u001b[39m.\u001b[39mhidden_dropout_prob)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:982\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39m=\u001b[39m BertPooler(config) \u001b[39mif\u001b[39;00m add_pooling_layer \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_implementation \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39m_attn_implementation\n\u001b[0;32m--> 982\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mposition_embedding_type\n\u001b[1;32m    984\u001b[0m \u001b[39m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_init()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/configuration_utils.py:202\u001b[0m, in \u001b[0;36mPretrainedConfig.__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mattribute_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mattribute_map\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    201\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mattribute_map\u001b[39m\u001b[39m\"\u001b[39m)[key]\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RetriBertConfig' object has no attribute 'position_embedding_type'"
     ]
    }
   ],
   "source": [
    " qar_tokenizer = AutoTokenizer.from_pretrained('yjernite/retribert-base-uncased')\n",
    "qar_model = AutoModel.from_pretrained('yjernite/retribert-base-uncased').to('mps')\n",
    "_ = qar_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
